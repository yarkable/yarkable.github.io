---
layout: post
title: Linux服务器管理员操作
subtitle: 
date: 2021-04-16
author: kevin
header-img: img/green-bg.jpg
catalog: true
tags:
    - linux
---



## 添加用户



由于每台服务器都需要连接到 NAS，而且可能很多用户在不同的服务器上都有账号，这样的话就会导致 uid 冲突（不同服务器上不同用户的 uid 可能是一样的），因此，针对不同情况需要用到不同添加用户的方法：

1. 该用户为新同学，说明他之前在其他服务器上没有账号，因此，先在 NAS 上为他开一个账号确保 uid 唯一性，再根据这个 uid 去其他的服务器上进行开号
2. 该用户在其他服务器上有账号，那就直接根据他的 uid 进行开号，无需再经过一遍 NAS



开号方式使用命令 `useradd` ，默认情况下直接 `useradd user1` 就可以了，用户目录为 `/home/user1`，但是考虑到服务器硬盘容量有限，最好将其划分到具有更大空间的目录如 `/data`，因此使用如下命令进行自定义添加用户



```shell
$ useradd -u [uid] -d /data/user1 -m -s /bin/bash user1
```



| 选项        | 含义                                                         |
| ----------- | ------------------------------------------------------------ |
| -u UID      | 手工指定用户的 UID，注意 UID 的范围（不要小于 500）。        |
| -d 主目录   | 手工指定用户的主目录。主目录必须写绝对路径，而且如果需要手工指定主目录，则一定要注意权限； |
| -c 用户说明 | 手工指定/etc/passwd文件中各用户信息中第 5 个字段的描述性内容，可随意配置； |
| -g 组名     | 手工指定用户的初始组。一般以和用户名相同的组作为用户的初始组，在创建用户时会默认建立初始组。一旦手动指定，则系统将不会在创建此默认的初始组目录。 |
| -G 组名     | 指定用户的附加组。我们把用户加入其他组，一般都使用附加组；   |
| -s shell    | 手工指定用户的登录 Shell，默认是 /bin/bash；                 |
| -e 曰期     | 指定用户的失效曰期，格式为 "YYYY-MM-DD"。也就是 /etc/shadow 文件的第八个字段； |
| -o          | 允许创建的用户的 UID 相同。例如，执行 "useradd -u 0 -o usertest" 命令建立用户 usertest，它的 UID 和 root 用户的 UID 相同，都是 0； |
| -m          | 建立用户时强制建立用户的家目录。在建立系统用户时，该选项是默认的； |
| -r          | 创建系统用户，也就是 UID 在 1~499 之间，供系统程序使用的用户。由于系统用户主要用于运行系统所需服务的权限配置，因此系统用户的创建默认不会创建主目录。 |

> 表格引自 http://c.biancheng.net/view/844.html



## 更新 CUDA

先装 CUDA [[下载地址](https://developer.nvidia.com/zh-cn/cuda-toolkit)]，老版本的 CUDA 不用删掉，直接让管理员将 cuda 软连接到最新的 CUDA 就行了，以防有些代码需要低版本 CUDA

再装驱动 [[驱动下载地址]](https://www.nvidia.cn/Download/index.aspx?lang=cn)，安装过程会提示说检测到老版本驱动，直接卸载就行了





## 常用命令



| 命令                                  | command                                           |
| ------------------------------------- | ------------------------------------------------- |
| 查看 GPU 使用状态                     | nvidia-smi 、 gpustat -i (需 pip install gpustat) |
| 查看进程                              | top、htop、ps -ef \| grep [pid]                   |
| 查看服务器磁盘容量                    | df -h                                             |
| 查看自己占用服务器的容量              | du -h                                             |
| 查看当前目录下文件个数 (不包含子目录) | ls -l \| grep "^-" \| wc -l                       |



## 换源



### pip 源



> vim ~/.pip/pip.conf

```txt
[global]

index-url = https://pypi.doubanio.com/simple

trusted-host = pypi.doubanio.com
```



### conda 源



> vim ~.condarc

```
channels:
  - defaults
show_channel_urls: true
default_channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
custom_channels:
  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
```



## 迁移 conda 环境



有时候我们需要在机器上重新建一个 conda 环境，但是又不想重新装包，毕竟 pytorch 和 cuda 版本都跟之前的环境是一样的，所以可以直接从之前的环境中复制一份成为新环境，conda 是支持这样做的，以下命令就将 BBB 环境拷贝了一份成为 AAA 环境。

```shell
conda create -n AAA -clone BBB
```

如果涉及不同服务器之间装环境的话也一样，可以先将旧的环境拷贝到新的电脑，然后通过下面的命令创一个新的环境

```shell
conda create -n AAA -clone ~/path
```

可以使用 `conda info -e`  来查询机器上的所有 conda 环境以及对应所在的位置。



## 挂载 NAS



其实就是将 NAS 上的目录映射到本地一个目录，所以新建一个目录叫做 `/NAS_REMOTE` ，用 apt 先安装 `nfs-utils` ，再 `sudo vim /etc/fstab` 在最底下添加一行 (前面是被挂载的目录，后面是本地挂载目录)

```
172.31.233.218:/share/CACHEDEV1_DATA/Public /NAS_REMOTE nfs defaults 0 0

```



之后再运行 `sudo mount -a` ，就能将 NAS 挂载上，以后重启机器的话也要运行一下这个命令进行挂载



> 挂载其他服务器 https://cshihong.github.io/2018/10/16/NFS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE/



## 批量 kill 进程 



用 grep 配合 awk 可以轻易做到，`awk '{print $2}'` 表示输出第二列结果，在 ps 命令中就是进程的 id 号

```shell
ps -ef | grep xxx | grep -v grep | awk '{print $2}' | xargs kill -9
```



## 莫名其妙占用显存



有时候明明没人用卡，但是卡的显存却被占用了很多，也找不到卡上的进程，这是因为上一个用卡的人的程序退出了，但是又没完全退出，让这个用户输入下面命令就可以清空显存（ 里面的 X 是 GPU 的 id 号 ），不过要注意，可能导致该用户所有 GPU 进程全部被终结，所以最好让该用户在没有使用 GPU 的时候输入命令

```bash
fuser -v /dev/nvidiaX | awk "{print $2}" | xargs kill -9
```





## 网络相关



### 86只能被233网段的机器连接



有时候重启了 233.86 之后，会出现 ssh 连接不上的情况，但是 233.xx 的 ip 可以连接上，这是因为 86 用的默认网卡是一张有问题的卡（不知道是谁设置的），默认走的是这张网卡，使用 `ip route` 命令可以看到，如果第一行的 default 不是连接到学校内网的网卡的话，就是有问题的，需要用 `ifconfig <网卡名> down` 把这块网卡关掉，然后再 `ip route` 查看，第一行 default 变了的话就是成功了



## 根目录列表无法显示



具体表现为，在根目录输入 `ls` 命令之后一直卡死，按 `CTRL+C` 都退不出去，没错，我说的就是 189 服务器。然后就输入 `df -h` 想看看服务器的磁盘使用情况，依然卡死，无法退出。于是查看一下本地的磁盘使用，输入 `df -hl` 有正常的输出，那就说明本地的文件系统没有问题，那么就可能是挂载了其他服务器上的磁盘，因为其他服务器出了问题，导致 `ls` 的时候一直在等待这个服务器的响应。于是输入 `mount` 查看服务器是否有挂载其他服务器文件夹，出来两个文件系统，一个是我们的 NAS，一个是师兄自己的 NAS，分别 ping 他们的 ip，都能 ping 通，所以不存在机器关机的问题，然后分别进入这两个文件夹，发现师兄的 NAS 可以正常进入，而我们的 NAS 进不去，并且一直卡着，那么问题找到了，我们的 NAS 出了问题。



怎么解决呢，一个好的办法就是将他取消挂载，但是用 `umount -f /NAS_REMOTE` 的话会说 `device is busy`，要用 `umount -l /NAS_REMOTE` ，这样就可以取消挂载，可以列出根目录列表了。随后检查一下 NAS，发现没有什么异常，在其他服务器取消挂载后再挂上去也一样正常，但是在 189 输入 `sudo mount -a` 重新挂载 NAS 后又会卡死，目前暂时未解决这个问题，估计重启后就可以了。



造成这种现象的原因是 nfs 服务器/网络挂了，nfs 客户端默认采用 hard-mount 选项，而不是 soft-mount。他们的区别是：

* soft-mount: 当客户端加载 NFS 不成功时，重试 retrans 设定的次数.如果 retrans 次都不成功，则放弃此操作，返回错误信息 "Connect time out"
* ard-mount: 当客户端加载 NFS 不成功时，一直重试，直到 NFS 服务器有响应。hard-mount 是系统的缺省值。
  

> reference：
>
> https://blog.csdn.net/Bronze5/article/details/79113378
>
> https://blog.csdn.net/qq_36270681/article/details/104408077
>
> https://blog.csdn.net/BrotherDong90/article/details/51735632



## A100 突然之间用不了GPU



经常在 A100 上发生，突然之间用不了 GPU 了，具体表现为，torch 的 `torch.cuda.is_available()` 为 False，并且运行英伟达的示例程序也 return 一个错误代码。花了些时间找出这是什么造成的，这是 A100 独有的问题，因为它需要一个 `fabricmanager` 服务，但是这个服务经常会突然崩掉，所以我们又得将这个服务重新安装，然后再 enable 它，GPU 就能够正常使用了。

```shell
distribution=$(. /etc/os-release;echo $ID$VERSION_ID | sed -e 's/\.//g') \
&& wget https://developer.download.nvidia.com/compute/cuda/repos/$distribution/x86_64/cuda-$distribution.pin \
&& sudo mv cuda-$distribution.pin /etc/apt/preferences.d/cuda-repository-pin-600

sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/$distribution/x86_64/7fa2af80.pub \
&& echo "deb http://developer.download.nvidia.com/compute/cuda/repos/$distribution/x86_64 /" | sudo tee /etc/apt/sources.list.d/cuda.list \
&& sudo apt-get update

sudo apt-cache madison cuda-drivers-fabricmanager-450

sudo apt-get install -y cuda-drivers-fabricmanager-450

reboot

systemctl start nvidia-fabricmanager.service
systemctl enable nvidia-fabricmanager.service
```





## 安全相关



1. 除非有特殊需要，否则禁止普通用户的 docker 权限！
2. 设置密码时不要太简单，应使用大小写字母加数字加特殊字符的组合
3. 校外访问如需用到内网穿透服务（如 frp，ngork 等），配置连接时应使用加密协议





Some pioneering work has been done to construct datasets
for human parts detection, but most of them are not
rich in human part categories. Vu et al. [1] introduce
a large dataset composed of 369,846 human heads annotated in 224,740 movie frames from 21 Hollywood movies,
which vary in genres and represent different time epochs.
Shao et al. [27] present the CrowdHuman dataset, providing
the annotation with both human bounding-box and head
bounding-box. For hand detection, Visual Geometry Group
introduces the VGGHand dataset [28], and became the most
crucial benchmark for human hand detection. VGGHand
contains about 11,194 images with 13,050 hand instances,
which is collected from various different public image data
set sources. EgoHands is another important human hand
detection dataset with high quality and pixel-level segmentation of hands, proposed by Bambach et al. [29]. It contains
4,800 frames from 48 Google Glass videos of complex, firstperson interactions between two people.

Unlike the above works, [26] and [3] are committed to
providing more comprehensive human parts detection data,
including but not limited to head, face, hand, and foot. HumanParts dataset is proposed by Li et al. [3], contains annotations
of three categories, including person, hand and face. This
is a large-scale dataset focused on human parts detection,
providing high-resolution 14,962 images with 106,879 annotations, the samples are randomly selected from AI Challenger
dataset [31]. Open Images [26] is a very large dataset with
object detection annotation. A subset of Open Images contains
5 human parts categories (person, head, face, hand, and foot)
of about 823,077 images, and has more than 4.7 million
detection annotations. This subset is currently the largest
human parts detection dataset, but there are some obvious
issues: serious data noise (many instances are not annotated),
extremely imbalanced annotation (eg., foot category accounts
for less than 0.05%) and lack of subordinate relationship.

